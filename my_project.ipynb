{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "233bb65d-12dc-43e7-a262-f07063abd5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data has been generated and saved to the SQLite database and CSV files.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from random import choices, randint\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Predefined genre-based title templates\n",
    "genre_titles = {\n",
    "    'Fiction': ['The Lost Horizon', 'Echoes of Eternity', 'Shadows of the Past', 'A Distant Journey', 'Whispers in the Wind'],\n",
    "    'Mystery': ['The Hidden Key', 'Murder on the Midnight Express', 'The Silent Witness', 'The Enigma Code', 'Undercover Shadows'],\n",
    "    'Fantasy': ['The Dragon’s Call', 'The Wizard’s Legacy', 'Chronicles of Eldoria', 'The Crystal Quest', 'The Sorcerer’s Stone'],\n",
    "    'Science Fiction': ['Galactic Wars', 'The AI Prophecy', 'Beyond the Stars', 'The Quantum Paradox', 'Terraformers'],\n",
    "    'Romance': ['A Love Unforeseen', 'Hearts Entwined', 'The Paris Affair', 'Whispered Promises', 'A Chance Encounter'],\n",
    "    'Non-Fiction': ['The Art of Mindfulness', 'Breaking Barriers', 'The Science of Sleep', 'A History of Empires', 'Innovations of Tomorrow'],\n",
    "    'Biography': ['The Life of a Visionary', 'Memoirs of a Maverick', 'The Untold Story', 'A Journey to Greatness', 'Living Legends'],\n",
    "    'Thriller': ['The Last Chase', 'Bloodlines', 'The Final Countdown', 'Deadly Pursuit', 'The Betrayal Pact']\n",
    "}\n",
    "\n",
    "# Generate Synthetic Book Data\n",
    "def generate_books(num_books=1000):\n",
    "    genres = list(genre_titles.keys())\n",
    "    countries = ['USA', 'UK', 'Canada', 'India', 'Australia', 'Germany', 'France', 'Japan']\n",
    "    \n",
    "    books = []\n",
    "    for _ in range(num_books):\n",
    "        genre = np.random.choice(genres)\n",
    "        title = np.random.choice(genre_titles[genre]) + f\" {fake.word().capitalize()}\"\n",
    "        author = fake.name()\n",
    "        year = np.random.randint(1950, 2023)\n",
    "        # 50% of books are from the USA\n",
    "        country = 'USA' if np.random.random() < 0.5 else np.random.choice(countries)\n",
    "        isbn = fake.unique.isbn10()\n",
    "        books.append([isbn, title, author, genre, year, country])\n",
    "    \n",
    "    return pd.DataFrame(books, columns=['ISBN', 'Title', 'Author', 'Genre', 'Year_of_Publication', 'Country'])\n",
    "\n",
    "# Generate Synthetic User Data\n",
    "def generate_users(num_users=10000, book_df=None):\n",
    "    if book_df is None:\n",
    "        raise ValueError(\"Book dataset is required to ensure consistency!\")\n",
    "    \n",
    "    genres = book_df['Genre'].unique()\n",
    "    countries = book_df['Country'].unique()\n",
    "    authors = book_df['Author'].unique()\n",
    "    decades = [(year // 10) * 10 for year in book_df['Year_of_Publication']]\n",
    "    decades = sorted(list(set(decades)))  # Unique decades\n",
    "    \n",
    "    users = {\n",
    "        'User_ID': range(1, num_users + 1),\n",
    "        'Age': np.random.randint(15, 80, num_users),\n",
    "        # 90% Male/Female, 10% Other\n",
    "        'Gender': np.random.choice(['Male', 'Female', 'Other'], p=[0.45, 0.45, 0.1], size=num_users),\n",
    "        'Country': np.random.choice(countries, num_users),\n",
    "        'Prefers_High_Rated_Books': np.random.choice(['Yes', 'No'], num_users),\n",
    "        'Preferred_Genres': [choices(genres, k=3) for _ in range(num_users)],  # Top 3 genres\n",
    "        'Preferred_Authors': [choices(authors, k=3) for _ in range(num_users)],  # Top 3 authors\n",
    "        'Preferred_Decade': np.random.choice(decades, num_users),\n",
    "        'Likes_Foreign_Books': np.random.choice(['Yes', 'No'], num_users)\n",
    "    }\n",
    "    # Join genres and authors as strings for readability\n",
    "    users['Preferred_Genres'] = [\", \".join(prefs) for prefs in users['Preferred_Genres']]\n",
    "    users['Preferred_Authors'] = [\", \".join(prefs) for prefs in users['Preferred_Authors']]\n",
    "    \n",
    "    return pd.DataFrame(users)\n",
    "\n",
    "#Generate Synthetic Ratings Data\n",
    "def generate_ratings(num_ratings=100000, book_df=None, user_df=None):\n",
    "    if book_df is None or user_df is None:\n",
    "        raise ValueError(\"Book and User datasets are required to generate ratings!\")\n",
    "    \n",
    "    ratings = {\n",
    "        'User_ID': np.random.choice(user_df['User_ID'], num_ratings),\n",
    "        'ISBN': np.random.choice(book_df['ISBN'], num_ratings),\n",
    "        'Rating': np.random.randint(1, 11, num_ratings)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(ratings)\n",
    "\n",
    "# Generate the data\n",
    "num_books = 1000\n",
    "num_users = 10000\n",
    "num_ratings = 100000\n",
    "\n",
    "books_df = generate_books(num_books=num_books)\n",
    "users_df = generate_users(num_users=num_users, book_df=books_df)\n",
    "ratings_df = generate_ratings(num_ratings=num_ratings, book_df=books_df, user_df=users_df)\n",
    "\n",
    "#Save Data to SQLite Database\n",
    "conn = sqlite3.connect(\"book_recommendation_system.db\")\n",
    "\n",
    "# Save DataFrames to SQLite tables\n",
    "books_df.to_sql(\"Books\", conn, if_exists=\"replace\", index=False)\n",
    "users_df.to_sql(\"Users\", conn, if_exists=\"replace\", index=False)\n",
    "ratings_df.to_sql(\"Ratings\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "books_df.to_csv(\"synthetic_books.csv\", index=False)\n",
    "users_df.to_csv(\"synthetic_users.csv\", index=False)\n",
    "ratings_df.to_csv(\"synthetic_ratings.csv\", index=False)\n",
    "\n",
    "print(\"Synthetic data has been generated and saved to the SQLite database and CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916bce42-993e-47bb-815c-5d6cec24d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Details:\n",
      "User ID: 10000\n",
      "Name: User_10000\n",
      "Age: 20\n",
      "Gender: Other\n",
      "Country: Canada\n",
      "Prefers High Rated Books: Yes\n",
      "Preferred Genres: Thriller, Fantasy, Thriller\n",
      "Preferred Authors: Natalie Shaw, Jessica Brown, Destiny Stuart DVM\n",
      "Preferred Decade: 2000\n",
      "Likes Foreign Books: No\n",
      "--------------------------------------------------\n",
      "\n",
      "Content-Based Recommendations:\n",
      "No strict matches found. Relaxing filters...\n",
      "                           Title             Author      Genre  \\\n",
      "901          The Last Chase Wear    Michael Johnson   Thriller   \n",
      "551   A Journey to Greatness Two  Michael Rodriguez  Biography   \n",
      "597  Memoirs of a Maverick Group       Mary Russell  Biography   \n",
      "106         Bloodlines Candidate       Jose Johnson   Thriller   \n",
      "802       The Betrayal Pact Than          Mary Dean   Thriller   \n",
      "\n",
      "     Year_of_Publication Country  \n",
      "901                 1970  Canada  \n",
      "551                 2002  Canada  \n",
      "597                 2002  Canada  \n",
      "106                 2015  Canada  \n",
      "802                 1973  Canada  \n",
      "\n",
      "Rating Recommendations:\n",
      "                           Title             Author            Genre  \\\n",
      "245  The Art of Mindfulness Year  Amanda Parker DVM      Non-Fiction   \n",
      "385    Beyond the Stars Majority  Christopher Davis  Science Fiction   \n",
      "441    A History of Empires Plan    Melanie Stewart      Non-Fiction   \n",
      "485    Undercover Shadows Budget      Pamela Powell          Mystery   \n",
      "503    The Sorcerer’s Stone Less       Joshua Olsen          Fantasy   \n",
      "\n",
      "     Year_of_Publication  Country  \n",
      "245                 1995      USA  \n",
      "385                 1982   Canada  \n",
      "441                 1983      USA  \n",
      "485                 2021      USA  \n",
      "503                 1967  Germany  \n",
      "\n",
      "Hybrid Recommendations:\n",
      "No strict matches found. Relaxing filters...\n",
      "                           Title             Author      Genre  \\\n",
      "901          The Last Chase Wear    Michael Johnson   Thriller   \n",
      "551   A Journey to Greatness Two  Michael Rodriguez  Biography   \n",
      "597  Memoirs of a Maverick Group       Mary Russell  Biography   \n",
      "106         Bloodlines Candidate       Jose Johnson   Thriller   \n",
      "802       The Betrayal Pact Than          Mary Dean   Thriller   \n",
      "\n",
      "     Year_of_Publication Country  \n",
      "901                 1970  Canada  \n",
      "551                 2002  Canada  \n",
      "597                 2002  Canada  \n",
      "106                 2015  Canada  \n",
      "802                 1973  Canada  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Connect to SQLite Database\n",
    "conn = sqlite3.connect(\"book_recommendation_system.db\")\n",
    "\n",
    "# Load data from the database\n",
    "books_df = pd.read_sql_query(\"SELECT * FROM Books\", conn)\n",
    "users_df = pd.read_sql_query(\"SELECT * FROM Users\", conn)\n",
    "ratings_df = pd.read_sql_query(\"SELECT * FROM Ratings\", conn)\n",
    "\n",
    "# Combine metadata for content-based filtering\n",
    "books_df['metadata'] = (\n",
    "    books_df['Genre'] + \" \" +\n",
    "    books_df['Author'] + \" \" +\n",
    "    books_df['Country'] + \" \" +\n",
    "    books_df['Year_of_Publication'].astype(str)\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorizer for content-based filtering (helps create my sythetic data)\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(books_df['metadata'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Display user details\n",
    "def display_user_details(user_id):\n",
    "    user_preferences = pd.read_sql_query(f\"SELECT * FROM Users WHERE User_ID = {user_id}\", conn).iloc[0]\n",
    "    print(\"User Details:\")\n",
    "    print(f\"User ID: {user_preferences['User_ID']}\")\n",
    "    print(f\"Name: User_{user_preferences['User_ID']}\")  # Simulated name\n",
    "    print(f\"Age: {user_preferences['Age']}\")\n",
    "    print(f\"Gender: {user_preferences['Gender']}\")\n",
    "    print(f\"Country: {user_preferences['Country']}\")\n",
    "    print(f\"Prefers High Rated Books: {user_preferences['Prefers_High_Rated_Books']}\")\n",
    "    print(f\"Preferred Genres: {user_preferences['Preferred_Genres']}\")\n",
    "    print(f\"Preferred Authors: {user_preferences['Preferred_Authors']}\")\n",
    "    print(f\"Preferred Decade: {user_preferences['Preferred_Decade']}\")\n",
    "    print(f\"Likes Foreign Books: {user_preferences['Likes_Foreign_Books']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Content-based recommendation function\n",
    "def recommend_books_content(user_id, top_n=5):\n",
    "    user_preferences = pd.read_sql_query(f\"SELECT * FROM Users WHERE User_ID = {user_id}\", conn).iloc[0]\n",
    "    preferred_genres = user_preferences['Preferred_Genres'].split(\", \")\n",
    "    preferred_authors = user_preferences['Preferred_Authors'].split(\", \")\n",
    "    preferred_decade = user_preferences['Preferred_Decade']\n",
    "    likes_foreign = user_preferences['Likes_Foreign_Books'] == \"Yes\"\n",
    "    user_country = user_preferences['Country']\n",
    "\n",
    "    # Apply strict filters\n",
    "    filtered_books = books_df[\n",
    "        (books_df['Genre'].isin(preferred_genres)) &\n",
    "        (books_df['Author'].isin(preferred_authors)) &\n",
    "        (books_df['Year_of_Publication'] // 10 * 10 == preferred_decade)\n",
    "    ]\n",
    "    if not likes_foreign:\n",
    "        filtered_books = filtered_books[filtered_books['Country'] == user_country]\n",
    "\n",
    "    # Relax filters if no matches\n",
    "    if filtered_books.empty:\n",
    "        print(\"No strict matches found. Relaxing filters...\")\n",
    "        filtered_books = books_df[\n",
    "            (books_df['Genre'].isin(preferred_genres)) |\n",
    "            (books_df['Author'].isin(preferred_authors)) |\n",
    "            (books_df['Year_of_Publication'] // 10 * 10 == preferred_decade)\n",
    "        ]\n",
    "        if not likes_foreign:\n",
    "            filtered_books = filtered_books[filtered_books['Country'] == user_country]\n",
    "\n",
    "    # Fallback to all books if still no matches\n",
    "    if filtered_books.empty:\n",
    "        print(\"No matches found even after relaxing filters. Using all books.\")\n",
    "        filtered_books = books_df\n",
    "\n",
    "    # Compute similarity for filtered books\n",
    "    indices = filtered_books.index\n",
    "    user_profile = cosine_sim[indices].mean(axis=0)\n",
    "    top_indices = np.argsort(user_profile)[::-1][:top_n]\n",
    "    return books_df.iloc[top_indices][['Title', 'Author', 'Genre', 'Year_of_Publication', 'Country']]\n",
    "\n",
    "# Rating-based recommendation function\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(ratings_df[['User_ID', 'ISBN', 'Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "\n",
    "def recommend_books_rating(user_id, top_n=5):\n",
    "    user_books = ratings_df[ratings_df['User_ID'] == user_id]['ISBN'].unique()\n",
    "    all_books = books_df['ISBN']\n",
    "    non_rated_books = [book for book in all_books if book not in user_books]\n",
    "    pred_ratings = [(book, model.predict(user_id, book).est) for book in non_rated_books]\n",
    "    pred_ratings = sorted(pred_ratings, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return books_df[books_df['ISBN'].isin([x[0] for x in pred_ratings])][['Title', 'Author', 'Genre', 'Year_of_Publication', 'Country']]\n",
    "\n",
    "# Hybrid recommendation\n",
    "def recommend_books_hybrid(user_id, top_n=5):\n",
    "    content_recommendations = recommend_books_content(user_id, top_n)\n",
    "    rating_recommendations = recommend_books_rating(user_id, top_n)\n",
    "    if isinstance(content_recommendations, str):\n",
    "        return rating_recommendations\n",
    "    hybrid_recommendations = pd.concat([content_recommendations, rating_recommendations])\n",
    "    hybrid_recommendations = hybrid_recommendations.drop_duplicates(subset='Title').head(top_n)\n",
    "    return hybrid_recommendations\n",
    "\n",
    "# Test (choose a user between 1 and 10,000)\n",
    "user_id = 10000\n",
    "display_user_details(user_id)\n",
    "\n",
    "print(\"\\nContent-Based Recommendations:\")\n",
    "print(recommend_books_content(user_id))\n",
    "\n",
    "print(\"\\nRating Recommendations:\")\n",
    "print(recommend_books_rating(user_id))\n",
    "\n",
    "print(\"\\nHybrid Recommendations:\")\n",
    "print(recommend_books_hybrid(user_id))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
